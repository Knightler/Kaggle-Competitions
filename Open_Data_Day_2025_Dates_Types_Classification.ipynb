{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOQc38BdPwhgC475vyYkuP6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Knightler/Kaggle-Competitions/blob/main/Open_Data_Day_2025_Dates_Types_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader, Subset, random_split\n",
        "from torch.optim.swa_utils import AveragedModel, SWALR, update_bn\n",
        "from PIL import Image\n",
        "import kagglehub"
      ],
      "metadata": {
        "id": "5kf6_H5ZHqwn"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------\n",
        "# Setup device and seeds\n",
        "# --------------------------\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "random.seed(42)"
      ],
      "metadata": {
        "id": "CEsZ0jeGJy_H"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------\n",
        "# Data Preparation\n",
        "# --------------------------\n",
        "data_dir = kagglehub.dataset_download(\"wadhasnalhamdan/date-fruit-image-dataset-in-controlled-environment\")\n",
        "print(\"Path to dataset files:\", data_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "py4_9GttTbAd",
        "outputId": "c70ef1c7-ed99-4bbf-cb12-f97222ce2727"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/wadhasnalhamdan/date-fruit-image-dataset-in-controlled-environment?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 92%|█████████▏| 2.86G/3.11G [01:38<00:08, 30.6MB/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "desired_classes = ['Ajwa', 'Nabtat Ali', 'Sokari']"
      ],
      "metadata": {
        "id": "Y7V9oOhdTvzO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.RandomRotation(30),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.RandomAffine(degrees=10, shear=5),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomVerticalFlip(p=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "JhFeqaOYTzlX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_transforms = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "PI-ZllU5T11e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_dataset = datasets.ImageFolder(root=data_dir, transform=train_transforms)"
      ],
      "metadata": {
        "id": "xEk0DNYNT3l9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "desired_idxs = [i for i, (_, label) in enumerate(full_dataset)\n",
        "                if full_dataset.classes[label] in desired_classes]\n",
        "subset_dataset = Subset(full_dataset, desired_idxs)"
      ],
      "metadata": {
        "id": "Ydy7YUVkT5Nd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(0.8 * len(subset_dataset))\n",
        "val_size = len(subset_dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(subset_dataset, [train_size, val_size])\n",
        "\n",
        "val_dataset.dataset.transform = val_transforms"
      ],
      "metadata": {
        "id": "P6gzYjReT7SR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,\n",
        "                          num_workers=4, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False,\n",
        "                        num_workers=4, pin_memory=True)"
      ],
      "metadata": {
        "id": "m-1mmX0YUAYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------\n",
        "# Model Definition: EfficientNet-B0\n",
        "# --------------------------\n",
        "from torchvision.models import efficientnet_b0\n",
        "model = efficientnet_b0(pretrained=True)\n",
        "num_ftrs = model.classifier[1].in_features\n",
        "model.classifier[1] = nn.Linear(num_ftrs, len(desired_classes))"
      ],
      "metadata": {
        "id": "ikE6cKD8U7gH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model.parameters():\n",
        "    param.requires_grad = True\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "nNoFx1z0U95P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------\n",
        "# Loss, Optimizer, and Scheduler\n",
        "# --------------------------\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=3, verbose=True)"
      ],
      "metadata": {
        "id": "suZgFDxAVAGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------\n",
        "# SWA Setup\n",
        "# --------------------------\n",
        "swa_model = AveragedModel(model)\n",
        "swa_scheduler = SWALR(optimizer, swa_lr=0.01, anneal_strategy=\"cos\", anneal_epochs=5)"
      ],
      "metadata": {
        "id": "9SqnXDS8VCUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------\n",
        "# MixUp Function\n",
        "# --------------------------\n",
        "def mixup_data(x, y, alpha=1.0):\n",
        "    if alpha > 0:\n",
        "        lam = np.random.beta(alpha, alpha)\n",
        "    else:\n",
        "        lam = 1\n",
        "    batch_size = x.size()[0]\n",
        "    index = torch.randperm(batch_size).to(device)\n",
        "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
        "    y_a, y_b = y, y[index]\n",
        "    return mixed_x, y_a, y_b, lam"
      ],
      "metadata": {
        "id": "C1x7hfQEVEm8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------\n",
        "# Training Loop with Early Stopping, MixUp, and SWA\n",
        "# --------------------------\n",
        "num_epochs = 30\n",
        "best_val_acc = 0.0\n",
        "early_stopping_counter = 0\n",
        "patience = 5\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Apply MixUp randomly 50% of the time\n",
        "        if random.random() > 0.5:\n",
        "            inputs_mixed, labels_a, labels_b, lam = mixup_data(inputs, labels, alpha=1.0)\n",
        "            outputs = model(inputs_mixed)\n",
        "            loss = lam * criterion(outputs, labels_a) + (1 - lam) * criterion(outputs, labels_b)\n",
        "        else:\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        running_corrects += (outputs.argmax(dim=1) == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_dataset)\n",
        "    epoch_acc = running_corrects / len(train_dataset)\n",
        "\n",
        "    # Validation Phase\n",
        "    model.eval()\n",
        "    val_corrects = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            val_corrects += (outputs.argmax(dim=1) == labels).sum().item()\n",
        "    val_acc = val_corrects / len(val_dataset)\n",
        "\n",
        "    # Step the scheduler\n",
        "    scheduler.step(val_acc)\n",
        "\n",
        "    # Early Stopping Check\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        torch.save(model.state_dict(), \"best_model.pth\")\n",
        "        early_stopping_counter = 0\n",
        "    else:\n",
        "        early_stopping_counter += 1\n",
        "\n",
        "    # Apply SWA during the last 5 epochs\n",
        "    if epoch >= (num_epochs - 5):\n",
        "        swa_model.update_parameters(model)\n",
        "        swa_scheduler.step()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {epoch_loss:.4f} - Train Acc: {epoch_acc:.4f} - Val Acc: {val_acc:.4f}\")\n",
        "\n",
        "    if early_stopping_counter >= patience:\n",
        "        print(\"Early stopping triggered!\")\n",
        "        break\n",
        "\n",
        "# Finalize SWA\n",
        "update_bn(train_loader, swa_model)\n",
        "torch.save(swa_model.state_dict(), \"swa_best_model.pth\")\n",
        "print(\"Training complete. Best model saved as 'best_model.pth' and SWA model as 'swa_best_model.pth'.\")"
      ],
      "metadata": {
        "id": "FCiauVS0VQtP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------\n",
        "# Test-Time Augmentation (TTA) for Prediction\n",
        "# --------------------------\n",
        "def predict_tta(image_path, model, transforms, class_names, num_augmentations=5):\n",
        "    model.eval()\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    predictions = []\n",
        "    for _ in range(num_augmentations):\n",
        "        img = transforms(image).unsqueeze(0).to(device)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(img)\n",
        "            _, pred = torch.max(outputs, 1)\n",
        "            predictions.append(pred.item())\n",
        "    final_prediction = max(set(predictions), key=predictions.count)\n",
        "    return class_names[final_prediction]"
      ],
      "metadata": {
        "id": "-2Qh5OpkVfb6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_to_idx = {cls: i for i, cls in enumerate(desired_classes)}\n",
        "idx_to_class = {v: k for k, v in class_to_idx.items()}"
      ],
      "metadata": {
        "id": "b5YqMpNWVg6W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}